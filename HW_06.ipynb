{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from stop_words import get_stop_words\n",
    "from string import punctuation\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 10000\n",
    "max_len = 100\n",
    "num_classes = 1\n",
    "\n",
    "# Training\n",
    "epochs = 20\n",
    "batch_size = 512\n",
    "print_batch_n = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('отзывы за лето.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>It just works!</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>В целом удобноное приложение...из минусов хотя...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Отлично все</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Стал зависать на 1% работы антивируса. Дальше ...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Очень удобно, работает быстро.</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                                            Content        Date\n",
       "0       5                                     It just works!  2017-08-14\n",
       "1       4  В целом удобноное приложение...из минусов хотя...  2017-08-14\n",
       "2       5                                        Отлично все  2017-08-14\n",
       "3       5  Стал зависать на 1% работы антивируса. Дальше ...  2017-08-14\n",
       "4       5                     Очень удобно, работает быстро.  2017-08-14"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Препроцессинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = set(punctuation)\n",
    "sw = set(get_stop_words(\"ru\"))\n",
    "morpher = MorphAnalyzer()\n",
    "\n",
    "def preprocess_text(txt):\n",
    "    txt = str(txt)\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub('https?://\\S+|www\\.\\S+', ' ', txt)\n",
    "    txt = re.sub(r'[^\\w\\s]',' ', txt)\n",
    "    txt = re.sub(r'[0-9]+', ' ', txt)\n",
    "    txt = re.sub('\\n', ' ', txt)\n",
    "    txt = re.sub(\"не\\s\", \"не\", txt)\n",
    "    txt = \"\".join(c for c in txt if c not in exclude)\n",
    "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
    "    return \" \".join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['Content'].apply(preprocess_text)\n",
    "data = data[data['Rating'] != 3]\n",
    "data['target'] = data['Rating'] > 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>It just works!</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>it just works</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>В целом удобноное приложение...из минусов хотя...</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>целое удобноной приложение минус хотеть большо...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Отлично все</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>отлично</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Стал зависать на 1% работы антивируса. Дальше ...</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>зависать работа антивирус ранее пользоваться н...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Очень удобно, работает быстро.</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>удобно работать быстро</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                                            Content        Date  \\\n",
       "0       5                                     It just works!  2017-08-14   \n",
       "1       4  В целом удобноное приложение...из минусов хотя...  2017-08-14   \n",
       "2       5                                        Отлично все  2017-08-14   \n",
       "3       5  Стал зависать на 1% работы антивируса. Дальше ...  2017-08-14   \n",
       "4       5                     Очень удобно, работает быстро.  2017-08-14   \n",
       "\n",
       "                                                text  target  \n",
       "0                                      it just works       1  \n",
       "1  целое удобноной приложение минус хотеть большо...       1  \n",
       "2                                            отлично       1  \n",
       "3  зависать работа антивирус ранее пользоваться н...       1  \n",
       "4                             удобно работать быстро       1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target'] = data['target'].astype(int)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиение на train и test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['text'], data['target'], test_size=0.2,\n",
    "                                                    random_state=13, stratify=data['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим корпус слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'классно невозможно использовать рутованный телефон работать нарекание отлично немочь понять заблокир'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus = ' '.join(X_train.values)\n",
    "train_corpus[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "# nltk.download(\"punkt\")\n",
    "\n",
    "tokens = word_tokenize(train_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отфильтруем данные\n",
    "\n",
    "и соберём в корпус N наиболее частых токенов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_filtered = [word for word in tokens if word.isalnum()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "dist = FreqDist(tokens_filtered)\n",
    "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7848"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens_filtered_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def text_to_sequence(text, maxlen):\n",
    "    result = []\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens_filtered = [word for word in tokens if word.isalnum()]\n",
    "    for word in tokens_filtered:\n",
    "        if word in vocabulary:\n",
    "            result.append(vocabulary[word])\n",
    "    padding = [0]*(maxlen-len(result))\n",
    "    return padding + result[-maxlen:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray([text_to_sequence(text, max_len) for text in X_train], dtype=np.int32)\n",
    "x_test = np.asarray([text_to_sequence(text, max_len) for text in X_test], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15798, 100)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, GlobalMaxPool1D, SimpleRNN, LSTM, GRU, Masking\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import TensorBoard \n",
    "from keras.objectives import categorical_crossentropy\n",
    "from keras.callbacks import EarlyStopping  \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15798, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=512, input_length=max_len))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "\n",
    "model.add(SimpleRNN(64))\n",
    "# model.add(Conv1D(128, 3))\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(AveragePooling1D())\n",
    "# model.add(Conv1D(256, 5))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(AveragePooling1D())\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Conv1D(128, 3))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(GlobalAveragePooling1D())\n",
    "# model.add(Dense(128, activation='relu', kernel_regularizer='l2'))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=loss,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "31/31 [==============================] - 10s 312ms/step - loss: 0.3664 - accuracy: 0.8410 - val_loss: 0.2546 - val_accuracy: 0.8851\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 9s 294ms/step - loss: 0.1993 - accuracy: 0.9213 - val_loss: 0.1762 - val_accuracy: 0.9248\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 9s 300ms/step - loss: 0.1259 - accuracy: 0.9520 - val_loss: 0.1684 - val_accuracy: 0.9284\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 9s 304ms/step - loss: 0.0838 - accuracy: 0.9696 - val_loss: 0.1873 - val_accuracy: 0.9281\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 9s 304ms/step - loss: 0.0556 - accuracy: 0.9817 - val_loss: 0.2083 - val_accuracy: 0.9243\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 9s 299ms/step - loss: 0.0358 - accuracy: 0.9899 - val_loss: 0.2397 - val_accuracy: 0.9248\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 9s 302ms/step - loss: 0.0265 - accuracy: 0.9925 - val_loss: 0.2639 - val_accuracy: 0.9197\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 10s 307ms/step - loss: 0.0210 - accuracy: 0.9941 - val_loss: 0.3035 - val_accuracy: 0.9177\n"
     ]
    }
   ],
   "source": [
    "tensorboard=TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
    "early_stopping=EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)  \n",
    "\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_val),\n",
    "                    callbacks=[tensorboard, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 105ms/step - loss: 0.1953 - accuracy: 0.9344\n",
      "494/494 [==============================] - 4s 9ms/step - loss: 0.0893 - accuracy: 0.9754\n",
      "\n",
      "\n",
      "Test score: 0.19525589048862457 \tTrain score:  0.08929198980331421\n",
      "Test accuracy: 0.9344303607940674 \tTrain accuracy:  0.9754399061203003\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_val, batch_size=batch_size, verbose=1)\n",
    "score_train = model.evaluate(x_train, y_train, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0], '\\tTrain score: ', score_train[0])\n",
    "print('Test accuracy:', score[1], '\\tTrain accuracy: ', score_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 96ms/step - loss: 0.1684 - accuracy: 0.9284\n",
      "494/494 [==============================] - 5s 10ms/step - loss: 0.0890 - accuracy: 0.9688\n",
      "\n",
      "\n",
      "Test score: 0.16840551793575287 \tTrain score:  0.08898252248764038\n",
      "Test accuracy: 0.9283544421195984 \tTrain accuracy:  0.968793511390686\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_val, batch_size=batch_size, verbose=1)\n",
    "score_train = model.evaluate(x_train, y_train, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0], '\\tTrain score: ', score_train[0])\n",
    "print('Test accuracy:', score[1], '\\tTrain accuracy: ', score_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=512, input_length=max_len))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "\n",
    "model.add(LSTM(64))\n",
    "# model.add(Conv1D(128, 3))\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(AveragePooling1D())\n",
    "# model.add(Conv1D(256, 5))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(AveragePooling1D())\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Conv1D(128, 3))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(GlobalAveragePooling1D())\n",
    "# model.add(Dense(128, activation='relu', kernel_regularizer='l2'))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=loss,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "31/31 [==============================] - 16s 508ms/step - loss: 0.4145 - accuracy: 0.8355 - val_loss: 0.2619 - val_accuracy: 0.8876\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 15s 480ms/step - loss: 0.2165 - accuracy: 0.9122 - val_loss: 0.1787 - val_accuracy: 0.9208\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 16s 501ms/step - loss: 0.1487 - accuracy: 0.9395 - val_loss: 0.1710 - val_accuracy: 0.9286\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 18s 569ms/step - loss: 0.1057 - accuracy: 0.9596 - val_loss: 0.1792 - val_accuracy: 0.9291\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 18s 566ms/step - loss: 0.0792 - accuracy: 0.9709 - val_loss: 0.2009 - val_accuracy: 0.9299\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 18s 575ms/step - loss: 0.0613 - accuracy: 0.9789 - val_loss: 0.2213 - val_accuracy: 0.9273\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 18s 569ms/step - loss: 0.0498 - accuracy: 0.9836 - val_loss: 0.2514 - val_accuracy: 0.9258\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 18s 569ms/step - loss: 0.0469 - accuracy: 0.9832 - val_loss: 0.2624 - val_accuracy: 0.9223\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 17s 560ms/step - loss: 0.0403 - accuracy: 0.9859 - val_loss: 0.2906 - val_accuracy: 0.9218\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 18s 583ms/step - loss: 0.0356 - accuracy: 0.9878 - val_loss: 0.3185 - val_accuracy: 0.9218\n"
     ]
    }
   ],
   "source": [
    "tensorboard=TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
    "early_stopping=EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)  \n",
    "\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_val),\n",
    "                    callbacks=[tensorboard, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 175ms/step - loss: 0.2009 - accuracy: 0.9299\n",
      "494/494 [==============================] - 10s 21ms/step - loss: 0.0593 - accuracy: 0.9815\n",
      "\n",
      "\n",
      "Test score: 0.2009226381778717 \tTrain score:  0.05926620587706566\n",
      "Test accuracy: 0.9298734068870544 \tTrain accuracy:  0.9815166592597961\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_val, batch_size=batch_size, verbose=1)\n",
    "score_train = model.evaluate(x_train, y_train, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0], '\\tTrain score: ', score_train[0])\n",
    "print('Test accuracy:', score[1], '\\tTrain accuracy: ', score_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=512, input_length=max_len))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "\n",
    "model.add(GRU(64))\n",
    "# model.add(Conv1D(128, 3))\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(AveragePooling1D())\n",
    "# model.add(Conv1D(256, 5))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(AveragePooling1D())\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Conv1D(128, 3))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(GlobalAveragePooling1D())\n",
    "# model.add(Dense(128, activation='relu', kernel_regularizer='l2'))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=loss,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "31/31 [==============================] - 16s 514ms/step - loss: 0.3925 - accuracy: 0.8482 - val_loss: 0.2363 - val_accuracy: 0.8985\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 15s 492ms/step - loss: 0.1952 - accuracy: 0.9231 - val_loss: 0.1808 - val_accuracy: 0.9225\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 15s 478ms/step - loss: 0.1413 - accuracy: 0.9445 - val_loss: 0.1768 - val_accuracy: 0.9210\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 15s 480ms/step - loss: 0.1048 - accuracy: 0.9596 - val_loss: 0.1978 - val_accuracy: 0.9246\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 15s 483ms/step - loss: 0.0764 - accuracy: 0.9723 - val_loss: 0.2283 - val_accuracy: 0.9220\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 15s 498ms/step - loss: 0.0596 - accuracy: 0.9793 - val_loss: 0.2554 - val_accuracy: 0.9195\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 15s 490ms/step - loss: 0.0521 - accuracy: 0.9808 - val_loss: 0.2828 - val_accuracy: 0.9157\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 15s 481ms/step - loss: 0.0435 - accuracy: 0.9853 - val_loss: 0.3020 - val_accuracy: 0.9190\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 15s 483ms/step - loss: 0.0372 - accuracy: 0.9874 - val_loss: 0.3331 - val_accuracy: 0.9147\n"
     ]
    }
   ],
   "source": [
    "tensorboard=TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
    "early_stopping=EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)  \n",
    "\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_val),\n",
    "                    callbacks=[tensorboard, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 138ms/step - loss: 0.1978 - accuracy: 0.9246\n",
      "494/494 [==============================] - 8s 16ms/step - loss: 0.0747 - accuracy: 0.9730\n",
      "\n",
      "\n",
      "Test score: 0.19778960943222046 \tTrain score:  0.07472924888134003\n",
      "Test accuracy: 0.9245569705963135 \tTrain accuracy:  0.9729712605476379\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_val, batch_size=batch_size, verbose=1)\n",
    "score_train = model.evaluate(x_train, y_train, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0], '\\tTrain score: ', score_train[0])\n",
    "print('Test accuracy:', score[1], '\\tTrain accuracy: ', score_train[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
