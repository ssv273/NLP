{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np\n",
    "from keras.callbacks import EarlyStopping \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 30\n",
    "latent_dim = 256\n",
    "num_samples = 10000\n",
    "data_path = 'data/rus-eng/rus.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Собираем из текстов токены и делаем pne-hot вектора на каждый токен\n",
    "\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text, _ = line.split('\\t')\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
    "    decoder_target_data[i, t:, target_token_index[' ']] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "125/125 [==============================] - 16s 132ms/step - loss: 1.1315 - accuracy: 0.7746 - val_loss: 0.9094 - val_accuracy: 0.7572\n",
      "Epoch 2/100\n",
      "125/125 [==============================] - 15s 121ms/step - loss: 0.7334 - accuracy: 0.8030 - val_loss: 0.7718 - val_accuracy: 0.7956\n",
      "Epoch 3/100\n",
      "125/125 [==============================] - 16s 130ms/step - loss: 0.6266 - accuracy: 0.8340 - val_loss: 0.6770 - val_accuracy: 0.8167\n",
      "Epoch 4/100\n",
      "125/125 [==============================] - 19s 151ms/step - loss: 0.5577 - accuracy: 0.8457 - val_loss: 0.6256 - val_accuracy: 0.8248\n",
      "Epoch 5/100\n",
      "125/125 [==============================] - 18s 144ms/step - loss: 0.6353 - accuracy: 0.8351 - val_loss: 0.6277 - val_accuracy: 0.8229\n",
      "Epoch 6/100\n",
      "125/125 [==============================] - 18s 147ms/step - loss: 0.5229 - accuracy: 0.8518 - val_loss: 0.6002 - val_accuracy: 0.8293\n",
      "Epoch 7/100\n",
      "125/125 [==============================] - 18s 147ms/step - loss: 0.5022 - accuracy: 0.8565 - val_loss: 0.5785 - val_accuracy: 0.8348\n",
      "Epoch 8/100\n",
      "125/125 [==============================] - 18s 145ms/step - loss: 0.4873 - accuracy: 0.8598 - val_loss: 0.5624 - val_accuracy: 0.8382\n",
      "Epoch 9/100\n",
      "125/125 [==============================] - 19s 148ms/step - loss: 0.4744 - accuracy: 0.8631 - val_loss: 0.5525 - val_accuracy: 0.8406\n",
      "Epoch 10/100\n",
      "125/125 [==============================] - 18s 141ms/step - loss: 0.4630 - accuracy: 0.8659 - val_loss: 0.5411 - val_accuracy: 0.8423\n",
      "Epoch 11/100\n",
      "125/125 [==============================] - 18s 144ms/step - loss: 0.4528 - accuracy: 0.8685 - val_loss: 0.5337 - val_accuracy: 0.8445\n",
      "Epoch 12/100\n",
      "125/125 [==============================] - 18s 145ms/step - loss: 0.4428 - accuracy: 0.8709 - val_loss: 0.5206 - val_accuracy: 0.8472\n",
      "Epoch 13/100\n",
      "125/125 [==============================] - 18s 142ms/step - loss: 0.4337 - accuracy: 0.8730 - val_loss: 0.5152 - val_accuracy: 0.8497\n",
      "Epoch 14/100\n",
      "125/125 [==============================] - 18s 144ms/step - loss: 0.4241 - accuracy: 0.8759 - val_loss: 0.5080 - val_accuracy: 0.8513\n",
      "Epoch 15/100\n",
      "125/125 [==============================] - 18s 143ms/step - loss: 0.4150 - accuracy: 0.8784 - val_loss: 0.4976 - val_accuracy: 0.8557\n",
      "Epoch 16/100\n",
      "125/125 [==============================] - 18s 145ms/step - loss: 0.4055 - accuracy: 0.8812 - val_loss: 0.4927 - val_accuracy: 0.8582\n",
      "Epoch 17/100\n",
      "125/125 [==============================] - 18s 143ms/step - loss: 0.3977 - accuracy: 0.8836 - val_loss: 0.4832 - val_accuracy: 0.8607\n",
      "Epoch 18/100\n",
      "125/125 [==============================] - 18s 146ms/step - loss: 0.3889 - accuracy: 0.8861 - val_loss: 0.4787 - val_accuracy: 0.8622\n",
      "Epoch 19/100\n",
      "125/125 [==============================] - 18s 142ms/step - loss: 0.3814 - accuracy: 0.8885 - val_loss: 0.4750 - val_accuracy: 0.8630\n",
      "Epoch 20/100\n",
      "125/125 [==============================] - 18s 144ms/step - loss: 0.3736 - accuracy: 0.8906 - val_loss: 0.4701 - val_accuracy: 0.8644\n",
      "Epoch 21/100\n",
      "125/125 [==============================] - 18s 144ms/step - loss: 0.3648 - accuracy: 0.8935 - val_loss: 0.4624 - val_accuracy: 0.8673\n",
      "Epoch 22/100\n",
      "125/125 [==============================] - 18s 145ms/step - loss: 0.3617 - accuracy: 0.8944 - val_loss: 0.4592 - val_accuracy: 0.8686\n",
      "Epoch 23/100\n",
      "125/125 [==============================] - 18s 143ms/step - loss: 0.3529 - accuracy: 0.8971 - val_loss: 0.4545 - val_accuracy: 0.8689\n",
      "Epoch 24/100\n",
      "125/125 [==============================] - 18s 144ms/step - loss: 0.3444 - accuracy: 0.8997 - val_loss: 0.4492 - val_accuracy: 0.8715\n",
      "Epoch 25/100\n",
      "125/125 [==============================] - 18s 146ms/step - loss: 0.3368 - accuracy: 0.9019 - val_loss: 0.4459 - val_accuracy: 0.8717\n",
      "Epoch 26/100\n",
      "125/125 [==============================] - 19s 149ms/step - loss: 0.3301 - accuracy: 0.9037 - val_loss: 0.4408 - val_accuracy: 0.8738\n",
      "Epoch 27/100\n",
      "125/125 [==============================] - 17s 140ms/step - loss: 0.3227 - accuracy: 0.9061 - val_loss: 0.4415 - val_accuracy: 0.8746\n",
      "Epoch 28/100\n",
      "125/125 [==============================] - 18s 146ms/step - loss: 0.3156 - accuracy: 0.9079 - val_loss: 0.4342 - val_accuracy: 0.8762\n",
      "Epoch 29/100\n",
      "125/125 [==============================] - 18s 145ms/step - loss: 0.3085 - accuracy: 0.9099 - val_loss: 0.4357 - val_accuracy: 0.8764\n",
      "Epoch 30/100\n",
      "125/125 [==============================] - 18s 143ms/step - loss: 0.3023 - accuracy: 0.9118 - val_loss: 0.4323 - val_accuracy: 0.8770\n",
      "Epoch 31/100\n",
      "125/125 [==============================] - 18s 143ms/step - loss: 0.2954 - accuracy: 0.9136 - val_loss: 0.4289 - val_accuracy: 0.8783\n",
      "Epoch 32/100\n",
      "125/125 [==============================] - 18s 148ms/step - loss: 0.2889 - accuracy: 0.9151 - val_loss: 0.4268 - val_accuracy: 0.8789\n",
      "Epoch 33/100\n",
      "125/125 [==============================] - 18s 142ms/step - loss: 0.2825 - accuracy: 0.9170 - val_loss: 0.4246 - val_accuracy: 0.8796\n",
      "Epoch 34/100\n",
      "125/125 [==============================] - 18s 144ms/step - loss: 0.2770 - accuracy: 0.9189 - val_loss: 0.4240 - val_accuracy: 0.8804\n",
      "Epoch 35/100\n",
      "125/125 [==============================] - 18s 143ms/step - loss: 0.2693 - accuracy: 0.9210 - val_loss: 0.4233 - val_accuracy: 0.8805\n",
      "Epoch 36/100\n",
      "125/125 [==============================] - 18s 145ms/step - loss: 0.2637 - accuracy: 0.9229 - val_loss: 0.4221 - val_accuracy: 0.8810\n",
      "Epoch 37/100\n",
      "125/125 [==============================] - 18s 148ms/step - loss: 0.2575 - accuracy: 0.9246 - val_loss: 0.4203 - val_accuracy: 0.8833\n",
      "Epoch 38/100\n",
      "125/125 [==============================] - 18s 142ms/step - loss: 0.2517 - accuracy: 0.9260 - val_loss: 0.4224 - val_accuracy: 0.8826\n",
      "Epoch 39/100\n",
      "125/125 [==============================] - 18s 144ms/step - loss: 0.2457 - accuracy: 0.9276 - val_loss: 0.4186 - val_accuracy: 0.8836\n",
      "Epoch 40/100\n",
      "125/125 [==============================] - 18s 144ms/step - loss: 0.2404 - accuracy: 0.9293 - val_loss: 0.4205 - val_accuracy: 0.8835\n",
      "Epoch 41/100\n",
      "125/125 [==============================] - 18s 143ms/step - loss: 0.2340 - accuracy: 0.9307 - val_loss: 0.4211 - val_accuracy: 0.8848\n",
      "Epoch 42/100\n",
      "125/125 [==============================] - 18s 144ms/step - loss: 0.2290 - accuracy: 0.9322 - val_loss: 0.4216 - val_accuracy: 0.8840\n",
      "Epoch 43/100\n",
      "125/125 [==============================] - 18s 144ms/step - loss: 0.2230 - accuracy: 0.9341 - val_loss: 0.4222 - val_accuracy: 0.8842\n",
      "Epoch 44/100\n",
      "125/125 [==============================] - 18s 144ms/step - loss: 0.2174 - accuracy: 0.9358 - val_loss: 0.4247 - val_accuracy: 0.8845\n",
      "-\n",
      "Input sentence: Go.\n",
      "Decoded sentence: Идите скорей.\n",
      "\n",
      "-\n",
      "Input sentence: Go.\n",
      "Decoded sentence: Идите скорей.\n",
      "\n",
      "-\n",
      "Input sentence: Go.\n",
      "Decoded sentence: Идите скорей.\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Подойдитесь.\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Подойдитесь.\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Подойдитесь.\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Подойдитесь.\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Подойдитесь.\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Беги!\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Беги!\n",
      "\n",
      "-\n",
      "Input sentence: Run.\n",
      "Decoded sentence: Беги!\n",
      "\n",
      "-\n",
      "Input sentence: Run.\n",
      "Decoded sentence: Беги!\n",
      "\n",
      "-\n",
      "Input sentence: Who?\n",
      "Decoded sentence: Кто такой визно?\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Эй, вставай!\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Эй, вставай!\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Эй, вставай!\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Эй, вставай!\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Эй, вставай!\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Эй, вставай!\n",
      "\n",
      "-\n",
      "Input sentence: Fire!\n",
      "Decoded sentence: Побудь скорее.\n",
      "\n",
      "-\n",
      "Input sentence: Fire!\n",
      "Decoded sentence: Побудь скорее.\n",
      "\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: Помогите мне!\n",
      "\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: Помогите мне!\n",
      "\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: Помогите мне!\n",
      "\n",
      "-\n",
      "Input sentence: Jump!\n",
      "Decoded sentence: Прысайте!\n",
      "\n",
      "-\n",
      "Input sentence: Jump!\n",
      "Decoded sentence: Прысайте!\n",
      "\n",
      "-\n",
      "Input sentence: Jump.\n",
      "Decoded sentence: Прысайте скойте!\n",
      "\n",
      "-\n",
      "Input sentence: Jump.\n",
      "Decoded sentence: Прысайте скойте!\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Перестаньте!\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Перестаньте!\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Перестаньте!\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Подожди!\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Подожди!\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Подожди!\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Подожди!\n",
      "\n",
      "-\n",
      "Input sentence: Wait.\n",
      "Decoded sentence: Подожди.\n",
      "\n",
      "-\n",
      "Input sentence: Wait.\n",
      "Decoded sentence: Подожди.\n",
      "\n",
      "-\n",
      "Input sentence: Wait.\n",
      "Decoded sentence: Подожди.\n",
      "\n",
      "-\n",
      "Input sentence: Do it.\n",
      "Decoded sentence: Сделайте это серчаной.\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: Идите спокой.\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: Идите спокой.\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: Помогите мне!\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: Помогите мне!\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: Помогите мне!\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: Помогите мне!\n",
      "\n",
      "-\n",
      "Input sentence: Hurry!\n",
      "Decoded sentence: Выстоните меня!\n",
      "\n",
      "-\n",
      "Input sentence: I ran.\n",
      "Decoded sentence: Я подождала.\n",
      "\n",
      "-\n",
      "Input sentence: I ran.\n",
      "Decoded sentence: Я подождала.\n",
      "\n",
      "-\n",
      "Input sentence: I ran.\n",
      "Decoded sentence: Я подождала.\n",
      "\n",
      "-\n",
      "Input sentence: I ran.\n",
      "Decoded sentence: Я подождала.\n",
      "\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence: Я спрослилась.\n",
      "\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence: Я спрослилась.\n",
      "\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence: Я спрослилась.\n",
      "\n",
      "-\n",
      "Input sentence: I try.\n",
      "Decoded sentence: Я попробовала.\n",
      "\n",
      "-\n",
      "Input sentence: I try.\n",
      "Decoded sentence: Я попробовала.\n",
      "\n",
      "-\n",
      "Input sentence: I try.\n",
      "Decoded sentence: Я попробовала.\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Я хочу уйти.\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Я хочу уйти.\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Я хочу уйти.\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Я хочу уйти.\n",
      "\n",
      "-\n",
      "Input sentence: Oh no!\n",
      "Decoded sentence: О не сорано!\n",
      "\n",
      "-\n",
      "Input sentence: Relax.\n",
      "Decoded sentence: Спасите \"де.\n",
      "\n",
      "-\n",
      "Input sentence: Relax.\n",
      "Decoded sentence: Спасите \"де.\n",
      "\n",
      "-\n",
      "Input sentence: Relax.\n",
      "Decoded sentence: Спасите \"де.\n",
      "\n",
      "-\n",
      "Input sentence: Shoot!\n",
      "Decoded sentence: Покажите!\n",
      "\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Поднимите его.\n",
      "\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Поднимите его.\n",
      "\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Поднимите его.\n",
      "\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Поднимите его.\n",
      "\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Поднимите его.\n",
      "\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Поднимите его.\n",
      "\n",
      "-\n",
      "Input sentence: Attack!\n",
      "Decoded sentence: Почистань!\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Ваше соросновое!\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Ваше соросновое!\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Ваше соросновое!\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Ваше соросновое!\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Ваше соросновое!\n",
      "\n",
      "-\n",
      "Input sentence: Eat it.\n",
      "Decoded sentence: Найдите это.\n",
      "\n",
      "-\n",
      "Input sentence: Eat up.\n",
      "Decoded sentence: Сделайте как.\n",
      "\n",
      "-\n",
      "Input sentence: Freeze!\n",
      "Decoded sentence: Веди на это!\n",
      "\n",
      "-\n",
      "Input sentence: Freeze!\n",
      "Decoded sentence: Веди на это!\n",
      "\n",
      "-\n",
      "Input sentence: Freeze!\n",
      "Decoded sentence: Веди на это!\n",
      "\n",
      "-\n",
      "Input sentence: Freeze!\n",
      "Decoded sentence: Веди на это!\n",
      "\n",
      "-\n",
      "Input sentence: Get up.\n",
      "Decoded sentence: Подолжайте.\n",
      "\n",
      "-\n",
      "Input sentence: Get up.\n",
      "Decoded sentence: Подолжайте.\n",
      "\n",
      "-\n",
      "Input sentence: Get up.\n",
      "Decoded sentence: Подолжайте.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Идите помой.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Идите помой.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Идите помой.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Идите помой.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Идите помой.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Идите помой.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Идите помой.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Идите помой.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Идите помой.\n",
      "\n",
      "-\n",
      "Input sentence: Got it!\n",
      "Decoded sentence: Пошли!\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Пошли!\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Пошли!\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Пошли!\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Пошли!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping=EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True) \n",
    "\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=100,\n",
    "          validation_split=0.2,\n",
    "         callbacks=[early_stopping])\n",
    "\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "for seq_index in range(100):\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поднимемся на уровень слов, чтобы можно было что-то более адекватное посчитать за адекватное время"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_path = 'data/rus-eng/rus.txt'\n",
    "num_samples = 10000\n",
    "\n",
    "# tf.enable_eager_execution()\n",
    "\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "#     w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    w = w.strip()\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w\n",
    "\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text, _ = line.split('\\t')\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(preprocess_sentence(input_text))\n",
    "    target_texts.append(preprocess_sentence(target_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> Ой <end>'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_sentence('Ой')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor, inp_lang_tokenizer = tokenize(input_texts)\n",
    "target_tensor, targ_lang_tokenizer = tokenize(target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "\n",
    "vocab_inp_size = len(inp_lang_tokenizer.word_index)+1\n",
    "vocab_tar_size = len(targ_lang_tokenizer.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.lstm(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))\n",
    "\n",
    "    \n",
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights\n",
    "    \n",
    "    \n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "        x = self.embedding(x)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        output, state = self.lstm(x)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        x = self.fc(output)\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "        dec_hidden = enc_hidden\n",
    "        dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "    \n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 1.3827\n",
      "Epoch 2 Loss 1.0388\n",
      "Epoch 3 Loss 0.8906\n",
      "Epoch 4 Loss 0.7632\n",
      "Epoch 5 Loss 0.6523\n",
      "Epoch 6 Loss 0.5510\n",
      "Epoch 7 Loss 0.4603\n",
      "Epoch 8 Loss 0.3772\n",
      "Epoch 9 Loss 0.3092\n",
      "Epoch 10 Loss 0.2569\n",
      "Epoch 11 Loss 0.2186\n",
      "Epoch 12 Loss 0.1951\n",
      "Epoch 13 Loss 0.1743\n",
      "Epoch 14 Loss 0.1595\n",
      "Epoch 15 Loss 0.1485\n",
      "Epoch 16 Loss 0.1412\n",
      "Epoch 17 Loss 0.1355\n",
      "Epoch 18 Loss 0.1316\n",
      "Epoch 19 Loss 0.1270\n",
      "Epoch 20 Loss 0.1230\n",
      "Epoch 21 Loss 0.1210\n",
      "Epoch 22 Loss 0.1179\n",
      "Epoch 23 Loss 0.1151\n",
      "Epoch 24 Loss 0.1140\n",
      "Epoch 25 Loss 0.1127\n",
      "Epoch 26 Loss 0.1124\n",
      "Epoch 27 Loss 0.1090\n",
      "Epoch 28 Loss 0.1081\n",
      "Epoch 29 Loss 0.1074\n",
      "Epoch 30 Loss 0.1060\n",
      "Epoch 31 Loss 0.1042\n",
      "Epoch 32 Loss 0.1052\n",
      "Epoch 33 Loss 0.1041\n",
      "Epoch 34 Loss 0.1030\n",
      "Epoch 35 Loss 0.1026\n",
      "Epoch 36 Loss 0.1014\n",
      "Epoch 37 Loss 0.1001\n",
      "Epoch 38 Loss 0.0995\n",
      "Epoch 39 Loss 0.0987\n",
      "Epoch 40 Loss 0.0978\n",
      "Epoch 41 Loss 0.0968\n",
      "Epoch 42 Loss 0.0960\n",
      "Epoch 43 Loss 0.0949\n",
      "Epoch 44 Loss 0.0943\n",
      "Epoch 45 Loss 0.0946\n",
      "Epoch 46 Loss 0.0937\n",
      "Epoch 47 Loss 0.0944\n",
      "Epoch 48 Loss 0.0935\n",
      "Epoch 49 Loss 0.0941\n",
      "Epoch 50 Loss 0.0925\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "for epoch in range(EPOCHS):\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "    \n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некоторые украденные функции для оценки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
    "\n",
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    inputs = [inp_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    result = ''\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += targ_lang_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "        if targ_lang_tokenizer.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "    return result, sentence, attention_plot\n",
    "\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "    fontdict = {'fontsize': 14}\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    plt.show()\n",
    "    \n",
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> cheers ! <end>\n",
      "Predicted translation: за ваше здоровье ! <end> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-61331b77bd12>:38: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
      "<ipython-input-29-61331b77bd12>:39: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ticker' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-d93729a0fb8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# %pylab inline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'cheers!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-61331b77bd12>\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicted translation: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mattention_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_plot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mplot_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_plot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-61331b77bd12>\u001b[0m in \u001b[0;36mplot_attention\u001b[0;34m(attention, sentence, predicted_sentence)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontdict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfontdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_yticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpredicted_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontdict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfontdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_major_locator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultipleLocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_major_locator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultipleLocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ticker' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %pylab inline\n",
    "\n",
    "translate(u'cheers!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"Calculate the attention weights.\n",
    "  q, k, v must have matching leading dimensions.\n",
    "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "  The mask has different shapes depending on its type(padding or look ahead) \n",
    "  but it must be broadcastable for addition.\n",
    "  \n",
    "  Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable \n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "    \n",
    "  Returns:\n",
    "    output, attention_weights\n",
    "    \"\"\"\n",
    "\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "  \n",
    "  # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "  # add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights\n",
    "    \n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2\n",
    "    \n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    \n",
    "    def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(\n",
    "            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2\n",
    "    \n",
    "    \n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                                self.d_model)\n",
    "\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # adding embedding and position encoding.\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                                 look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "\n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                               input_vocab_size, pe_input, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                               target_vocab_size, pe_target, rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "    def call(self, inp, tar, training, enc_padding_mask, \n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, attention_weights = self.decoder(\n",
    "            tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = len(inp_lang_tokenizer.index_word) + 2\n",
    "target_vocab_size = len(targ_lang_tokenizer.index_word) + 2\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "  \n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "  \n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')\n",
    "\n",
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          pe_input=input_vocab_size, \n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "  \n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "  \n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(inp, tar_inp, \n",
    "                                 True, \n",
    "                                 enc_padding_mask, \n",
    "                                 combined_mask, \n",
    "                                 dec_padding_mask)\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "  \n",
    "    train_loss(loss)\n",
    "    train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 8.5511 Accuracy 0.0000\n",
      "Epoch 1 Batch 50 Loss 8.3694 Accuracy 0.0103\n",
      "Epoch 1 Batch 100 Loss 8.0927 Accuracy 0.0375\n",
      "Epoch 1 Loss 7.9865 Accuracy 0.0445\n",
      "Epoch 2 Batch 0 Loss 7.4731 Accuracy 0.0745\n",
      "Epoch 2 Batch 50 Loss 7.2935 Accuracy 0.0780\n",
      "Epoch 2 Batch 100 Loss 7.0874 Accuracy 0.0931\n",
      "Epoch 2 Loss 6.9657 Accuracy 0.1016\n",
      "Epoch 3 Batch 0 Loss 6.2584 Accuracy 0.1406\n",
      "Epoch 3 Batch 50 Loss 5.9902 Accuracy 0.1470\n",
      "Epoch 3 Batch 100 Loss 5.7054 Accuracy 0.1531\n",
      "Epoch 3 Loss 5.5750 Accuracy 0.1544\n",
      "Epoch 4 Batch 0 Loss 4.7785 Accuracy 0.1623\n",
      "Epoch 4 Batch 50 Loss 4.6117 Accuracy 0.1649\n",
      "Epoch 4 Batch 100 Loss 4.4224 Accuracy 0.1668\n",
      "Epoch 4 Loss 4.3393 Accuracy 0.1679\n",
      "Epoch 5 Batch 0 Loss 3.8173 Accuracy 0.1743\n",
      "Epoch 5 Batch 50 Loss 3.7521 Accuracy 0.1763\n",
      "Epoch 5 Batch 100 Loss 3.6597 Accuracy 0.1786\n",
      "Epoch 5 Loss 3.6180 Accuracy 0.1801\n",
      "Epoch 6 Batch 0 Loss 3.2982 Accuracy 0.1935\n",
      "Epoch 6 Batch 50 Loss 3.3064 Accuracy 0.1914\n",
      "Epoch 6 Batch 100 Loss 3.2611 Accuracy 0.1920\n",
      "Epoch 6 Loss 3.2348 Accuracy 0.1927\n",
      "Epoch 7 Batch 0 Loss 2.9752 Accuracy 0.2043\n",
      "Epoch 7 Batch 50 Loss 3.0060 Accuracy 0.1974\n",
      "Epoch 7 Batch 100 Loss 2.9926 Accuracy 0.1984\n",
      "Epoch 7 Loss 2.9753 Accuracy 0.1990\n",
      "Epoch 8 Batch 0 Loss 3.0393 Accuracy 0.1863\n",
      "Epoch 8 Batch 50 Loss 2.8229 Accuracy 0.2018\n",
      "Epoch 8 Batch 100 Loss 2.7824 Accuracy 0.2038\n",
      "Epoch 8 Loss 2.7741 Accuracy 0.2040\n",
      "Epoch 9 Batch 0 Loss 2.6560 Accuracy 0.2103\n",
      "Epoch 9 Batch 50 Loss 2.6289 Accuracy 0.2087\n",
      "Epoch 9 Batch 100 Loss 2.6083 Accuracy 0.2087\n",
      "Epoch 9 Loss 2.6054 Accuracy 0.2083\n",
      "Epoch 10 Batch 0 Loss 2.4761 Accuracy 0.2163\n",
      "Epoch 10 Batch 50 Loss 2.4680 Accuracy 0.2113\n",
      "Epoch 10 Batch 100 Loss 2.4563 Accuracy 0.2115\n",
      "Epoch 10 Loss 2.4554 Accuracy 0.2113\n",
      "Epoch 11 Batch 0 Loss 2.3709 Accuracy 0.2163\n",
      "Epoch 11 Batch 50 Loss 2.3058 Accuracy 0.2154\n",
      "Epoch 11 Batch 100 Loss 2.3101 Accuracy 0.2151\n",
      "Epoch 11 Loss 2.3111 Accuracy 0.2152\n",
      "Epoch 12 Batch 0 Loss 2.0984 Accuracy 0.2212\n",
      "Epoch 12 Batch 50 Loss 2.1884 Accuracy 0.2181\n",
      "Epoch 12 Batch 100 Loss 2.1845 Accuracy 0.2184\n",
      "Epoch 12 Loss 2.1766 Accuracy 0.2186\n",
      "Epoch 13 Batch 0 Loss 1.9447 Accuracy 0.2296\n",
      "Epoch 13 Batch 50 Loss 2.0391 Accuracy 0.2217\n",
      "Epoch 13 Batch 100 Loss 2.0432 Accuracy 0.2223\n",
      "Epoch 13 Loss 2.0396 Accuracy 0.2230\n",
      "Epoch 14 Batch 0 Loss 1.8794 Accuracy 0.2200\n",
      "Epoch 14 Batch 50 Loss 1.8708 Accuracy 0.2280\n",
      "Epoch 14 Batch 100 Loss 1.8958 Accuracy 0.2279\n",
      "Epoch 14 Loss 1.9025 Accuracy 0.2278\n",
      "Epoch 15 Batch 0 Loss 1.9289 Accuracy 0.2248\n",
      "Epoch 15 Batch 50 Loss 1.7836 Accuracy 0.2319\n",
      "Epoch 15 Batch 100 Loss 1.7855 Accuracy 0.2314\n",
      "Epoch 15 Loss 1.7768 Accuracy 0.2319\n",
      "Epoch 16 Batch 0 Loss 1.5699 Accuracy 0.2308\n",
      "Epoch 16 Batch 50 Loss 1.6325 Accuracy 0.2361\n",
      "Epoch 16 Batch 100 Loss 1.6617 Accuracy 0.2345\n",
      "Epoch 16 Loss 1.6608 Accuracy 0.2342\n",
      "Epoch 17 Batch 0 Loss 1.4259 Accuracy 0.2440\n",
      "Epoch 17 Batch 50 Loss 1.5169 Accuracy 0.2401\n",
      "Epoch 17 Batch 100 Loss 1.5336 Accuracy 0.2393\n",
      "Epoch 17 Loss 1.5339 Accuracy 0.2395\n",
      "Epoch 18 Batch 0 Loss 1.2766 Accuracy 0.2608\n",
      "Epoch 18 Batch 50 Loss 1.3853 Accuracy 0.2468\n",
      "Epoch 18 Batch 100 Loss 1.4072 Accuracy 0.2446\n",
      "Epoch 18 Loss 1.4218 Accuracy 0.2435\n",
      "Epoch 19 Batch 0 Loss 1.1432 Accuracy 0.2560\n",
      "Epoch 19 Batch 50 Loss 1.2743 Accuracy 0.2509\n",
      "Epoch 19 Batch 100 Loss 1.3002 Accuracy 0.2492\n",
      "Epoch 19 Loss 1.3159 Accuracy 0.2477\n",
      "Epoch 20 Batch 0 Loss 1.1184 Accuracy 0.2644\n",
      "Epoch 20 Batch 50 Loss 1.1718 Accuracy 0.2562\n",
      "Epoch 20 Batch 100 Loss 1.1942 Accuracy 0.2538\n",
      "Epoch 20 Loss 1.2074 Accuracy 0.2527\n",
      "Epoch 21 Batch 0 Loss 1.0281 Accuracy 0.2656\n",
      "Epoch 21 Batch 50 Loss 1.0662 Accuracy 0.2608\n",
      "Epoch 21 Batch 100 Loss 1.0920 Accuracy 0.2582\n",
      "Epoch 21 Loss 1.1050 Accuracy 0.2569\n",
      "Epoch 22 Batch 0 Loss 1.0001 Accuracy 0.2608\n",
      "Epoch 22 Batch 50 Loss 0.9869 Accuracy 0.2633\n",
      "Epoch 22 Batch 100 Loss 1.0193 Accuracy 0.2601\n",
      "Epoch 22 Loss 1.0376 Accuracy 0.2590\n",
      "Epoch 23 Batch 0 Loss 0.9079 Accuracy 0.2584\n",
      "Epoch 23 Batch 50 Loss 0.8923 Accuracy 0.2670\n",
      "Epoch 23 Batch 100 Loss 0.9280 Accuracy 0.2646\n",
      "Epoch 23 Loss 0.9479 Accuracy 0.2630\n",
      "Epoch 24 Batch 0 Loss 0.7568 Accuracy 0.2885\n",
      "Epoch 24 Batch 50 Loss 0.8217 Accuracy 0.2724\n",
      "Epoch 24 Batch 100 Loss 0.8740 Accuracy 0.2667\n",
      "Epoch 24 Loss 0.8885 Accuracy 0.2659\n",
      "Epoch 25 Batch 0 Loss 0.7491 Accuracy 0.2764\n",
      "Epoch 25 Batch 50 Loss 0.7580 Accuracy 0.2766\n",
      "Epoch 25 Batch 100 Loss 0.8136 Accuracy 0.2700\n",
      "Epoch 25 Loss 0.8351 Accuracy 0.2683\n",
      "Epoch 26 Batch 0 Loss 0.6161 Accuracy 0.2897\n",
      "Epoch 26 Batch 50 Loss 0.6918 Accuracy 0.2788\n",
      "Epoch 26 Batch 100 Loss 0.7591 Accuracy 0.2736\n",
      "Epoch 26 Loss 0.7782 Accuracy 0.2721\n",
      "Epoch 27 Batch 0 Loss 0.6515 Accuracy 0.2849\n",
      "Epoch 27 Batch 50 Loss 0.6740 Accuracy 0.2813\n",
      "Epoch 27 Batch 100 Loss 0.7293 Accuracy 0.2749\n",
      "Epoch 27 Loss 0.7570 Accuracy 0.2723\n",
      "Epoch 28 Batch 0 Loss 0.6530 Accuracy 0.2752\n",
      "Epoch 28 Batch 50 Loss 0.6382 Accuracy 0.2816\n",
      "Epoch 28 Batch 100 Loss 0.6945 Accuracy 0.2763\n",
      "Epoch 28 Loss 0.7154 Accuracy 0.2749\n",
      "Epoch 29 Batch 0 Loss 0.5101 Accuracy 0.2788\n",
      "Epoch 29 Batch 50 Loss 0.6165 Accuracy 0.2840\n",
      "Epoch 29 Batch 100 Loss 0.6743 Accuracy 0.2776\n",
      "Epoch 29 Loss 0.6993 Accuracy 0.2756\n",
      "Epoch 30 Batch 0 Loss 0.5252 Accuracy 0.2873\n",
      "Epoch 30 Batch 50 Loss 0.6076 Accuracy 0.2846\n",
      "Epoch 30 Batch 100 Loss 0.6674 Accuracy 0.2790\n",
      "Epoch 30 Loss 0.6846 Accuracy 0.2774\n",
      "Epoch 31 Batch 0 Loss 0.5800 Accuracy 0.2776\n",
      "Epoch 31 Batch 50 Loss 0.5908 Accuracy 0.2843\n",
      "Epoch 31 Batch 100 Loss 0.6430 Accuracy 0.2800\n",
      "Epoch 31 Loss 0.6691 Accuracy 0.2780\n",
      "Epoch 32 Batch 0 Loss 0.5330 Accuracy 0.2812\n",
      "Epoch 32 Batch 50 Loss 0.5727 Accuracy 0.2858\n",
      "Epoch 32 Batch 100 Loss 0.6393 Accuracy 0.2798\n",
      "Epoch 32 Loss 0.6639 Accuracy 0.2779\n",
      "Epoch 33 Batch 0 Loss 0.4744 Accuracy 0.2849\n",
      "Epoch 33 Batch 50 Loss 0.5859 Accuracy 0.2841\n",
      "Epoch 33 Batch 100 Loss 0.6292 Accuracy 0.2807\n",
      "Epoch 33 Loss 0.6505 Accuracy 0.2793\n",
      "Epoch 34 Batch 0 Loss 0.5689 Accuracy 0.2825\n",
      "Epoch 34 Batch 50 Loss 0.5415 Accuracy 0.2864\n",
      "Epoch 34 Batch 100 Loss 0.5935 Accuracy 0.2831\n",
      "Epoch 34 Loss 0.6172 Accuracy 0.2816\n",
      "Epoch 35 Batch 0 Loss 0.4940 Accuracy 0.2957\n",
      "Epoch 35 Batch 50 Loss 0.5325 Accuracy 0.2893\n",
      "Epoch 35 Batch 100 Loss 0.5959 Accuracy 0.2826\n",
      "Epoch 35 Loss 0.6096 Accuracy 0.2819\n",
      "Epoch 36 Batch 0 Loss 0.4405 Accuracy 0.2921\n",
      "Epoch 36 Batch 50 Loss 0.5249 Accuracy 0.2890\n",
      "Epoch 36 Batch 100 Loss 0.5723 Accuracy 0.2854\n",
      "Epoch 36 Loss 0.5884 Accuracy 0.2839\n",
      "Epoch 37 Batch 0 Loss 0.4427 Accuracy 0.3005\n",
      "Epoch 37 Batch 50 Loss 0.5006 Accuracy 0.2893\n",
      "Epoch 37 Batch 100 Loss 0.5485 Accuracy 0.2865\n",
      "Epoch 37 Loss 0.5709 Accuracy 0.2850\n",
      "Epoch 38 Batch 0 Loss 0.4621 Accuracy 0.2921\n",
      "Epoch 38 Batch 50 Loss 0.4919 Accuracy 0.2910\n",
      "Epoch 38 Batch 100 Loss 0.5460 Accuracy 0.2867\n",
      "Epoch 38 Loss 0.5647 Accuracy 0.2854\n",
      "Epoch 39 Batch 0 Loss 0.4530 Accuracy 0.3017\n",
      "Epoch 39 Batch 50 Loss 0.4665 Accuracy 0.2926\n",
      "Epoch 39 Batch 100 Loss 0.5238 Accuracy 0.2892\n",
      "Epoch 39 Loss 0.5431 Accuracy 0.2872\n",
      "Epoch 40 Batch 0 Loss 0.3972 Accuracy 0.3077\n",
      "Epoch 40 Batch 50 Loss 0.4870 Accuracy 0.2929\n",
      "Epoch 40 Batch 100 Loss 0.5262 Accuracy 0.2886\n",
      "Epoch 40 Loss 0.5455 Accuracy 0.2872\n",
      "Epoch 41 Batch 0 Loss 0.3528 Accuracy 0.2885\n",
      "Epoch 41 Batch 50 Loss 0.4534 Accuracy 0.2963\n",
      "Epoch 41 Batch 100 Loss 0.5077 Accuracy 0.2907\n",
      "Epoch 41 Loss 0.5242 Accuracy 0.2891\n",
      "Epoch 42 Batch 0 Loss 0.3395 Accuracy 0.3053\n",
      "Epoch 42 Batch 50 Loss 0.4406 Accuracy 0.2953\n",
      "Epoch 42 Batch 100 Loss 0.4966 Accuracy 0.2902\n",
      "Epoch 42 Loss 0.5156 Accuracy 0.2891\n",
      "Epoch 43 Batch 0 Loss 0.3676 Accuracy 0.3089\n",
      "Epoch 43 Batch 50 Loss 0.4515 Accuracy 0.2935\n",
      "Epoch 43 Batch 100 Loss 0.4974 Accuracy 0.2905\n",
      "Epoch 43 Loss 0.5148 Accuracy 0.2892\n",
      "Epoch 44 Batch 0 Loss 0.4422 Accuracy 0.2933\n",
      "Epoch 44 Batch 50 Loss 0.4397 Accuracy 0.2941\n",
      "Epoch 44 Batch 100 Loss 0.4885 Accuracy 0.2910\n",
      "Epoch 44 Loss 0.5059 Accuracy 0.2901\n",
      "Epoch 45 Batch 0 Loss 0.3145 Accuracy 0.3113\n",
      "Epoch 45 Batch 50 Loss 0.4304 Accuracy 0.2956\n",
      "Epoch 45 Batch 100 Loss 0.4718 Accuracy 0.2928\n",
      "Epoch 45 Loss 0.4909 Accuracy 0.2914\n",
      "Epoch 46 Batch 0 Loss 0.3605 Accuracy 0.3041\n",
      "Epoch 46 Batch 50 Loss 0.4269 Accuracy 0.2954\n",
      "Epoch 46 Batch 100 Loss 0.4673 Accuracy 0.2924\n",
      "Epoch 46 Loss 0.4839 Accuracy 0.2911\n",
      "Epoch 47 Batch 0 Loss 0.3715 Accuracy 0.2897\n",
      "Epoch 47 Batch 50 Loss 0.4203 Accuracy 0.2955\n",
      "Epoch 47 Batch 100 Loss 0.4614 Accuracy 0.2929\n",
      "Epoch 47 Loss 0.4767 Accuracy 0.2918\n",
      "Epoch 48 Batch 0 Loss 0.3241 Accuracy 0.3077\n",
      "Epoch 48 Batch 50 Loss 0.4131 Accuracy 0.2974\n",
      "Epoch 48 Batch 100 Loss 0.4632 Accuracy 0.2936\n",
      "Epoch 48 Loss 0.4790 Accuracy 0.2924\n",
      "Epoch 49 Batch 0 Loss 0.3577 Accuracy 0.3101\n",
      "Epoch 49 Batch 50 Loss 0.4023 Accuracy 0.2997\n",
      "Epoch 49 Batch 100 Loss 0.4452 Accuracy 0.2948\n",
      "Epoch 49 Loss 0.4667 Accuracy 0.2929\n",
      "Epoch 50 Batch 0 Loss 0.3360 Accuracy 0.3137\n",
      "Epoch 50 Batch 50 Loss 0.3945 Accuracy 0.2994\n",
      "Epoch 50 Batch 100 Loss 0.4411 Accuracy 0.2954\n",
      "Epoch 50 Loss 0.4590 Accuracy 0.2938\n",
      "Epoch 51 Batch 0 Loss 0.3060 Accuracy 0.3137\n",
      "Epoch 51 Batch 50 Loss 0.3981 Accuracy 0.2985\n",
      "Epoch 51 Batch 100 Loss 0.4434 Accuracy 0.2944\n",
      "Epoch 51 Loss 0.4600 Accuracy 0.2932\n",
      "Epoch 52 Batch 0 Loss 0.3775 Accuracy 0.3125\n",
      "Epoch 52 Batch 50 Loss 0.3863 Accuracy 0.3013\n",
      "Epoch 52 Batch 100 Loss 0.4301 Accuracy 0.2960\n",
      "Epoch 52 Loss 0.4494 Accuracy 0.2941\n",
      "Epoch 53 Batch 0 Loss 0.3173 Accuracy 0.3065\n",
      "Epoch 53 Batch 50 Loss 0.3910 Accuracy 0.2983\n",
      "Epoch 53 Batch 100 Loss 0.4372 Accuracy 0.2944\n",
      "Epoch 53 Loss 0.4523 Accuracy 0.2936\n",
      "Epoch 54 Batch 0 Loss 0.4223 Accuracy 0.2969\n",
      "Epoch 54 Batch 50 Loss 0.3768 Accuracy 0.3011\n",
      "Epoch 54 Batch 100 Loss 0.4209 Accuracy 0.2963\n",
      "Epoch 54 Loss 0.4416 Accuracy 0.2949\n",
      "Epoch 55 Batch 0 Loss 0.4276 Accuracy 0.2981\n",
      "Epoch 55 Batch 50 Loss 0.3844 Accuracy 0.2980\n",
      "Epoch 55 Batch 100 Loss 0.4276 Accuracy 0.2948\n",
      "Epoch 55 Loss 0.4449 Accuracy 0.2936\n",
      "Epoch 56 Batch 0 Loss 0.3775 Accuracy 0.3053\n",
      "Epoch 56 Batch 50 Loss 0.3742 Accuracy 0.2989\n",
      "Epoch 56 Batch 100 Loss 0.4125 Accuracy 0.2964\n",
      "Epoch 56 Loss 0.4317 Accuracy 0.2950\n",
      "Epoch 57 Batch 0 Loss 0.3150 Accuracy 0.3089\n",
      "Epoch 57 Batch 50 Loss 0.3777 Accuracy 0.2983\n",
      "Epoch 57 Batch 100 Loss 0.4185 Accuracy 0.2954\n",
      "Epoch 57 Loss 0.4339 Accuracy 0.2942\n",
      "Epoch 58 Batch 0 Loss 0.3237 Accuracy 0.3065\n",
      "Epoch 58 Batch 50 Loss 0.3733 Accuracy 0.2999\n",
      "Epoch 58 Batch 100 Loss 0.4116 Accuracy 0.2961\n",
      "Epoch 58 Loss 0.4253 Accuracy 0.2956\n",
      "Epoch 59 Batch 0 Loss 0.2961 Accuracy 0.3161\n",
      "Epoch 59 Batch 50 Loss 0.3734 Accuracy 0.2993\n",
      "Epoch 59 Batch 100 Loss 0.4095 Accuracy 0.2963\n",
      "Epoch 59 Loss 0.4255 Accuracy 0.2950\n",
      "Epoch 60 Batch 0 Loss 0.3797 Accuracy 0.2933\n",
      "Epoch 60 Batch 50 Loss 0.3587 Accuracy 0.3003\n",
      "Epoch 60 Batch 100 Loss 0.4055 Accuracy 0.2972\n",
      "Epoch 60 Loss 0.4218 Accuracy 0.2955\n",
      "Epoch 61 Batch 0 Loss 0.4260 Accuracy 0.3041\n",
      "Epoch 61 Batch 50 Loss 0.3642 Accuracy 0.3008\n",
      "Epoch 61 Batch 100 Loss 0.4033 Accuracy 0.2971\n",
      "Epoch 61 Loss 0.4175 Accuracy 0.2958\n",
      "Epoch 62 Batch 0 Loss 0.2981 Accuracy 0.3137\n",
      "Epoch 62 Batch 50 Loss 0.3592 Accuracy 0.3005\n",
      "Epoch 62 Batch 100 Loss 0.3926 Accuracy 0.2981\n",
      "Epoch 62 Loss 0.4093 Accuracy 0.2964\n",
      "Epoch 63 Batch 0 Loss 0.3436 Accuracy 0.3029\n",
      "Epoch 63 Batch 50 Loss 0.3609 Accuracy 0.3010\n",
      "Epoch 63 Batch 100 Loss 0.3989 Accuracy 0.2971\n",
      "Epoch 63 Loss 0.4139 Accuracy 0.2961\n",
      "Epoch 64 Batch 0 Loss 0.3242 Accuracy 0.3101\n",
      "Epoch 64 Batch 50 Loss 0.3569 Accuracy 0.3009\n",
      "Epoch 64 Batch 100 Loss 0.3990 Accuracy 0.2972\n",
      "Epoch 64 Loss 0.4128 Accuracy 0.2962\n",
      "Epoch 65 Batch 0 Loss 0.3119 Accuracy 0.3017\n",
      "Epoch 65 Batch 50 Loss 0.3452 Accuracy 0.3021\n",
      "Epoch 65 Batch 100 Loss 0.3877 Accuracy 0.2979\n",
      "Epoch 65 Loss 0.4049 Accuracy 0.2966\n",
      "Epoch 66 Batch 0 Loss 0.3225 Accuracy 0.3137\n",
      "Epoch 66 Batch 50 Loss 0.3597 Accuracy 0.3010\n",
      "Epoch 66 Batch 100 Loss 0.3897 Accuracy 0.2985\n",
      "Epoch 66 Loss 0.4024 Accuracy 0.2975\n",
      "Epoch 67 Batch 0 Loss 0.3218 Accuracy 0.2812\n",
      "Epoch 67 Batch 50 Loss 0.3493 Accuracy 0.3017\n",
      "Epoch 67 Batch 100 Loss 0.3878 Accuracy 0.2980\n",
      "Epoch 67 Loss 0.4010 Accuracy 0.2969\n",
      "Epoch 68 Batch 0 Loss 0.2754 Accuracy 0.3005\n",
      "Epoch 68 Batch 50 Loss 0.3485 Accuracy 0.3010\n",
      "Epoch 68 Batch 100 Loss 0.3863 Accuracy 0.2977\n",
      "Epoch 68 Loss 0.3984 Accuracy 0.2964\n",
      "Epoch 69 Batch 0 Loss 0.2356 Accuracy 0.3077\n",
      "Epoch 69 Batch 50 Loss 0.3479 Accuracy 0.3004\n",
      "Epoch 69 Batch 100 Loss 0.3801 Accuracy 0.2986\n",
      "Epoch 69 Loss 0.3958 Accuracy 0.2973\n",
      "Epoch 70 Batch 0 Loss 0.2692 Accuracy 0.3185\n",
      "Epoch 70 Batch 50 Loss 0.3352 Accuracy 0.3028\n",
      "Epoch 70 Batch 100 Loss 0.3774 Accuracy 0.2989\n",
      "Epoch 70 Loss 0.3897 Accuracy 0.2982\n",
      "Epoch 71 Batch 0 Loss 0.3482 Accuracy 0.3065\n",
      "Epoch 71 Batch 50 Loss 0.3387 Accuracy 0.3032\n",
      "Epoch 71 Batch 100 Loss 0.3761 Accuracy 0.2994\n",
      "Epoch 71 Loss 0.3917 Accuracy 0.2976\n",
      "Epoch 72 Batch 0 Loss 0.3516 Accuracy 0.3029\n",
      "Epoch 72 Batch 50 Loss 0.3319 Accuracy 0.3035\n",
      "Epoch 72 Batch 100 Loss 0.3745 Accuracy 0.2992\n",
      "Epoch 72 Loss 0.3899 Accuracy 0.2978\n",
      "Epoch 73 Batch 0 Loss 0.2061 Accuracy 0.3257\n",
      "Epoch 73 Batch 50 Loss 0.3255 Accuracy 0.3041\n",
      "Epoch 73 Batch 100 Loss 0.3716 Accuracy 0.2991\n",
      "Epoch 73 Loss 0.3860 Accuracy 0.2980\n",
      "Epoch 74 Batch 0 Loss 0.3555 Accuracy 0.2897\n",
      "Epoch 74 Batch 50 Loss 0.3327 Accuracy 0.3031\n",
      "Epoch 74 Batch 100 Loss 0.3698 Accuracy 0.2996\n",
      "Epoch 74 Loss 0.3847 Accuracy 0.2982\n",
      "Epoch 75 Batch 0 Loss 0.2630 Accuracy 0.3101\n",
      "Epoch 75 Batch 50 Loss 0.3241 Accuracy 0.3043\n",
      "Epoch 75 Batch 100 Loss 0.3705 Accuracy 0.2994\n",
      "Epoch 75 Loss 0.3802 Accuracy 0.2986\n",
      "Epoch 76 Batch 0 Loss 0.2836 Accuracy 0.2945\n",
      "Epoch 76 Batch 50 Loss 0.3309 Accuracy 0.3026\n",
      "Epoch 76 Batch 100 Loss 0.3656 Accuracy 0.2992\n",
      "Epoch 76 Loss 0.3799 Accuracy 0.2981\n",
      "Epoch 77 Batch 0 Loss 0.2999 Accuracy 0.3017\n",
      "Epoch 77 Batch 50 Loss 0.3329 Accuracy 0.3025\n",
      "Epoch 77 Batch 100 Loss 0.3624 Accuracy 0.3003\n",
      "Epoch 77 Loss 0.3773 Accuracy 0.2985\n",
      "Epoch 78 Batch 0 Loss 0.3207 Accuracy 0.3005\n",
      "Epoch 78 Batch 50 Loss 0.3331 Accuracy 0.3018\n",
      "Epoch 78 Batch 100 Loss 0.3616 Accuracy 0.2992\n",
      "Epoch 78 Loss 0.3750 Accuracy 0.2982\n",
      "Epoch 79 Batch 0 Loss 0.2591 Accuracy 0.3149\n",
      "Epoch 79 Batch 50 Loss 0.3193 Accuracy 0.3028\n",
      "Epoch 79 Batch 100 Loss 0.3585 Accuracy 0.2989\n",
      "Epoch 79 Loss 0.3725 Accuracy 0.2980\n",
      "Epoch 80 Batch 0 Loss 0.2354 Accuracy 0.3113\n",
      "Epoch 80 Batch 50 Loss 0.3180 Accuracy 0.3022\n",
      "Epoch 80 Batch 100 Loss 0.3575 Accuracy 0.2994\n",
      "Epoch 80 Loss 0.3712 Accuracy 0.2984\n",
      "Epoch 81 Batch 0 Loss 0.3193 Accuracy 0.2945\n",
      "Epoch 81 Batch 50 Loss 0.3147 Accuracy 0.3025\n",
      "Epoch 81 Batch 100 Loss 0.3569 Accuracy 0.2995\n",
      "Epoch 81 Loss 0.3683 Accuracy 0.2985\n",
      "Epoch 82 Batch 0 Loss 0.3098 Accuracy 0.3173\n",
      "Epoch 82 Batch 50 Loss 0.3242 Accuracy 0.3034\n",
      "Epoch 82 Batch 100 Loss 0.3534 Accuracy 0.3001\n",
      "Epoch 82 Loss 0.3701 Accuracy 0.2984\n",
      "Epoch 83 Batch 0 Loss 0.2513 Accuracy 0.3161\n",
      "Epoch 83 Batch 50 Loss 0.3255 Accuracy 0.3026\n",
      "Epoch 83 Batch 100 Loss 0.3559 Accuracy 0.3005\n",
      "Epoch 83 Loss 0.3680 Accuracy 0.2986\n",
      "Epoch 84 Batch 0 Loss 0.3121 Accuracy 0.3065\n",
      "Epoch 84 Batch 50 Loss 0.3147 Accuracy 0.3043\n",
      "Epoch 84 Batch 100 Loss 0.3442 Accuracy 0.3009\n",
      "Epoch 84 Loss 0.3645 Accuracy 0.2990\n",
      "Epoch 85 Batch 0 Loss 0.2584 Accuracy 0.3209\n",
      "Epoch 85 Batch 50 Loss 0.3135 Accuracy 0.3038\n",
      "Epoch 85 Batch 100 Loss 0.3483 Accuracy 0.3002\n",
      "Epoch 85 Loss 0.3632 Accuracy 0.2988\n",
      "Epoch 86 Batch 0 Loss 0.2858 Accuracy 0.3065\n",
      "Epoch 86 Batch 50 Loss 0.3094 Accuracy 0.3041\n",
      "Epoch 86 Batch 100 Loss 0.3457 Accuracy 0.3006\n",
      "Epoch 86 Loss 0.3608 Accuracy 0.2989\n",
      "Epoch 87 Batch 0 Loss 0.2746 Accuracy 0.3089\n",
      "Epoch 87 Batch 50 Loss 0.3114 Accuracy 0.3039\n",
      "Epoch 87 Batch 100 Loss 0.3474 Accuracy 0.2998\n",
      "Epoch 87 Loss 0.3630 Accuracy 0.2984\n",
      "Epoch 88 Batch 0 Loss 0.2678 Accuracy 0.3161\n",
      "Epoch 88 Batch 50 Loss 0.3035 Accuracy 0.3043\n",
      "Epoch 88 Batch 100 Loss 0.3356 Accuracy 0.3013\n",
      "Epoch 88 Loss 0.3547 Accuracy 0.2992\n",
      "Epoch 89 Batch 0 Loss 0.2570 Accuracy 0.3149\n",
      "Epoch 89 Batch 50 Loss 0.3109 Accuracy 0.3019\n",
      "Epoch 89 Batch 100 Loss 0.3424 Accuracy 0.2996\n",
      "Epoch 89 Loss 0.3590 Accuracy 0.2985\n",
      "Epoch 90 Batch 0 Loss 0.2383 Accuracy 0.3185\n",
      "Epoch 90 Batch 50 Loss 0.3062 Accuracy 0.3048\n",
      "Epoch 90 Batch 100 Loss 0.3453 Accuracy 0.3003\n",
      "Epoch 90 Loss 0.3600 Accuracy 0.2987\n",
      "Epoch 91 Batch 0 Loss 0.2503 Accuracy 0.3221\n",
      "Epoch 91 Batch 50 Loss 0.3055 Accuracy 0.3049\n",
      "Epoch 91 Batch 100 Loss 0.3386 Accuracy 0.3005\n",
      "Epoch 91 Loss 0.3515 Accuracy 0.2993\n",
      "Epoch 92 Batch 0 Loss 0.2746 Accuracy 0.3005\n",
      "Epoch 92 Batch 50 Loss 0.3108 Accuracy 0.3030\n",
      "Epoch 92 Batch 100 Loss 0.3404 Accuracy 0.3004\n",
      "Epoch 92 Loss 0.3533 Accuracy 0.2989\n",
      "Epoch 93 Batch 0 Loss 0.2488 Accuracy 0.3209\n",
      "Epoch 93 Batch 50 Loss 0.3059 Accuracy 0.3035\n",
      "Epoch 93 Batch 100 Loss 0.3380 Accuracy 0.3004\n",
      "Epoch 93 Loss 0.3507 Accuracy 0.2994\n",
      "Epoch 94 Batch 0 Loss 0.2450 Accuracy 0.3113\n",
      "Epoch 94 Batch 50 Loss 0.2969 Accuracy 0.3046\n",
      "Epoch 94 Batch 100 Loss 0.3381 Accuracy 0.3003\n",
      "Epoch 94 Loss 0.3505 Accuracy 0.2997\n",
      "Epoch 95 Batch 0 Loss 0.2921 Accuracy 0.3077\n",
      "Epoch 95 Batch 50 Loss 0.3021 Accuracy 0.3036\n",
      "Epoch 95 Batch 100 Loss 0.3341 Accuracy 0.3008\n",
      "Epoch 95 Loss 0.3496 Accuracy 0.2991\n",
      "Epoch 96 Batch 0 Loss 0.3424 Accuracy 0.2837\n",
      "Epoch 96 Batch 50 Loss 0.3019 Accuracy 0.3039\n",
      "Epoch 96 Batch 100 Loss 0.3381 Accuracy 0.3006\n",
      "Epoch 96 Loss 0.3538 Accuracy 0.2992\n",
      "Epoch 97 Batch 0 Loss 0.2312 Accuracy 0.3209\n",
      "Epoch 97 Batch 50 Loss 0.2933 Accuracy 0.3049\n",
      "Epoch 97 Batch 100 Loss 0.3300 Accuracy 0.3009\n",
      "Epoch 97 Loss 0.3447 Accuracy 0.2994\n",
      "Epoch 98 Batch 0 Loss 0.2719 Accuracy 0.2993\n",
      "Epoch 98 Batch 50 Loss 0.2975 Accuracy 0.3035\n",
      "Epoch 98 Batch 100 Loss 0.3286 Accuracy 0.3013\n",
      "Epoch 98 Loss 0.3440 Accuracy 0.2998\n",
      "Epoch 99 Batch 0 Loss 0.2158 Accuracy 0.3245\n",
      "Epoch 99 Batch 50 Loss 0.2985 Accuracy 0.3042\n",
      "Epoch 99 Batch 100 Loss 0.3302 Accuracy 0.3010\n",
      "Epoch 99 Loss 0.3452 Accuracy 0.2995\n",
      "Epoch 100 Batch 0 Loss 0.2557 Accuracy 0.3137\n",
      "Epoch 100 Batch 50 Loss 0.2962 Accuracy 0.3032\n",
      "Epoch 100 Batch 100 Loss 0.3309 Accuracy 0.3012\n",
      "Epoch 100 Loss 0.3415 Accuracy 0.3000\n"
     ]
    }
   ],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "  \n",
    "  # add extra dimensions to add the padding\n",
    "  # to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)\n",
    "\n",
    "for epoch in range(100):\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "  \n",
    "    for (batch, (inp, tar)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        train_step(inp, tar)\n",
    "        if batch % 50 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "              epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "    \n",
    "    print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: good morning.\n",
      "Predicted translation: ['<start>', 'доброе', 'утро', '.']\n"
     ]
    }
   ],
   "source": [
    "def evaluate(inp_sentence):\n",
    "    start_token = [1]\n",
    "    end_token = [2]\n",
    "  \n",
    "    sentence = preprocess_sentence(inp_sentence)\n",
    "    inputs = [inp_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "    \n",
    "    encoder_input = tf.expand_dims(inputs, 0)\n",
    "  \n",
    "  # as the target is english, the first word to the transformer should be the\n",
    "  # english start token.\n",
    "    decoder_input = [1]\n",
    "    output = tf.expand_dims(decoder_input, 0)\n",
    "    \n",
    "    for i in range(max_length_targ):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "            encoder_input, output)\n",
    "  \n",
    "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "        predictions, attention_weights = transformer(encoder_input, \n",
    "                                                 output,\n",
    "                                                 False,\n",
    "                                                 enc_padding_mask,\n",
    "                                                 combined_mask,\n",
    "                                                 dec_padding_mask)\n",
    "    \n",
    "    # select the last word from the seq_len dimension\n",
    "        predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "    \n",
    "    # return the result if the predicted_id is equal to the end token\n",
    "        if predicted_id == targ_lang_tokenizer.word_index[\"<end>\"]:\n",
    "            return tf.squeeze(output, axis=0), attention_weights\n",
    "    \n",
    "    # concatentate the predicted_id to the output which is given to the decoder\n",
    "    # as its input.\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output, axis=0), attention_weights\n",
    "\n",
    "\n",
    "def plot_attention_weights(attention, sentence, result, layer):\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "  \n",
    "    sentence = inp_lang_tokenizer.encode(sentence)\n",
    "  \n",
    "    attention = tf.squeeze(attention[layer], axis=0)\n",
    "  \n",
    "    for head in range(attention.shape[0]):\n",
    "        ax = fig.add_subplot(2, 4, head+1)\n",
    "\n",
    "        # plot the attention weights\n",
    "        ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
    "\n",
    "        fontdict = {'fontsize': 10}\n",
    "\n",
    "        ax.set_xticks(range(len(sentence)+2))\n",
    "        ax.set_yticks(range(len(result)))\n",
    "\n",
    "        ax.set_ylim(len(result)-1.5, -0.5)\n",
    "\n",
    "        ax.set_xticklabels(\n",
    "            ['<start>']+[tokenizer_pt.decode([i]) for i in sentence]+['<end>'], \n",
    "            fontdict=fontdict, rotation=90)\n",
    "\n",
    "        ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n",
    "                            if i < tokenizer_en.vocab_size], \n",
    "                           fontdict=fontdict)\n",
    "\n",
    "        ax.set_xlabel('Head {}'.format(head+1))\n",
    "  \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def translate(sentence, plot=''):\n",
    "    result, attention_weights = evaluate(sentence)\n",
    "    predicted_sentence = ([targ_lang_tokenizer.index_word[i] for i in result.numpy()])  \n",
    "\n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Predicted translation: {}'.format(predicted_sentence))\n",
    "  \n",
    "    if plot:\n",
    "        plot_attention_weights(attention_weights, sentence, result, plot)\n",
    "        \n",
    "translate(\"good morning.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: how are you?\n",
      "Predicted translation: ['<start>', 'как', 'твоё', 'ничего', '?']\n"
     ]
    }
   ],
   "source": [
    "translate(\"how are you?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
