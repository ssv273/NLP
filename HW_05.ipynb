{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание из 2-х частей.\n",
    "Берем отызывы за лето (из архива с материалами или предыдущего занятия)\n",
    "1. Учим conv сеть для классификации - выбить auc выше 0.95\n",
    "2. Предобучаем word2vec и его эмбединга инициализируем сетку, как влияет на качество?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from stop_words import get_stop_words\n",
    "from string import punctuation\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 10000\n",
    "max_len = 100\n",
    "num_classes = 1\n",
    "\n",
    "# Training\n",
    "epochs = 20\n",
    "batch_size = 512\n",
    "print_batch_n = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('отзывы за лето.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>It just works!</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>В целом удобноное приложение...из минусов хотя...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Отлично все</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Стал зависать на 1% работы антивируса. Дальше ...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Очень удобно, работает быстро.</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                                            Content        Date\n",
       "0       5                                     It just works!  2017-08-14\n",
       "1       4  В целом удобноное приложение...из минусов хотя...  2017-08-14\n",
       "2       5                                        Отлично все  2017-08-14\n",
       "3       5  Стал зависать на 1% работы антивируса. Дальше ...  2017-08-14\n",
       "4       5                     Очень удобно, работает быстро.  2017-08-14"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Препроцессинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = set(punctuation)\n",
    "sw = set(get_stop_words(\"ru\"))\n",
    "morpher = MorphAnalyzer()\n",
    "\n",
    "def preprocess_text(txt):\n",
    "    txt = str(txt)\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub('https?://\\S+|www\\.\\S+', ' ', txt)\n",
    "    txt = re.sub(r'[^\\w\\s]',' ', txt)\n",
    "    txt = re.sub(r'[0-9]+', ' ', txt)\n",
    "    txt = re.sub('\\n', ' ', txt)\n",
    "    txt = re.sub(\"не\\s\", \"не\", txt)\n",
    "    txt = \"\".join(c for c in txt if c not in exclude)\n",
    "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
    "    return \" \".join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['Content'].apply(preprocess_text)\n",
    "data = data[data['Rating'] != 3]\n",
    "data['target'] = data['Rating'] > 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>It just works!</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>it just works</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>В целом удобноное приложение...из минусов хотя...</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>целое удобноной приложение минус хотеть большо...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Отлично все</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>отлично</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Стал зависать на 1% работы антивируса. Дальше ...</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>зависать работа антивирус ранее пользоваться н...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Очень удобно, работает быстро.</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>удобно работать быстро</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                                            Content        Date  \\\n",
       "0       5                                     It just works!  2017-08-14   \n",
       "1       4  В целом удобноное приложение...из минусов хотя...  2017-08-14   \n",
       "2       5                                        Отлично все  2017-08-14   \n",
       "3       5  Стал зависать на 1% работы антивируса. Дальше ...  2017-08-14   \n",
       "4       5                     Очень удобно, работает быстро.  2017-08-14   \n",
       "\n",
       "                                                text  target  \n",
       "0                                      it just works       1  \n",
       "1  целое удобноной приложение минус хотеть большо...       1  \n",
       "2                                            отлично       1  \n",
       "3  зависать работа антивирус ранее пользоваться н...       1  \n",
       "4                             удобно работать быстро       1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target'] = data['target'].astype(int)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиение на train и test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['text'], data['target'], test_size=0.2,\n",
    "                                                    random_state=13, stratify=data['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим корпус слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'классно невозможно использовать рутованный телефон работать нарекание отлично немочь понять заблокир'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus = ' '.join(X_train.values)\n",
    "train_corpus[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "# nltk.download(\"punkt\")\n",
    "\n",
    "tokens = word_tokenize(train_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отфильтруем данные\n",
    "\n",
    "и соберём в корпус N наиболее частых токенов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_filtered = [word for word in tokens if word.isalnum()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "dist = FreqDist(tokens_filtered)\n",
    "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7848"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens_filtered_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def text_to_sequence(text, maxlen):\n",
    "    result = []\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens_filtered = [word for word in tokens if word.isalnum()]\n",
    "    for word in tokens_filtered:\n",
    "        if word in vocabulary:\n",
    "            result.append(vocabulary[word])\n",
    "    padding = [0]*(maxlen-len(result))\n",
    "    return padding + result[-maxlen:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray([text_to_sequence(text, max_len) for text in X_train], dtype=np.int32)\n",
    "x_test = np.asarray([text_to_sequence(text, max_len) for text in X_test], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15798, 100)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, GlobalMaxPool1D, AveragePooling1D, GlobalAveragePooling1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import TensorBoard \n",
    "from keras.objectives import categorical_crossentropy\n",
    "from keras.callbacks import EarlyStopping  \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15798, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=512, input_length=max_len))\n",
    "model.add(Conv1D(128, 3))\n",
    "model.add(Activation(\"relu\"))\n",
    "# model.add(AveragePooling1D())\n",
    "# model.add(Conv1D(256, 5))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(AveragePooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "# model.add(Conv1D(128, 3))\n",
    "# model.add(Activation('relu'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer='l2'))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=loss,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 1/31 [..............................] - ETA: 0s - loss: 1.9784 - accuracy: 0.1113WARNING:tensorflow:From /media/ssv/SHARED/GEEKBRAINS/env/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "31/31 [==============================] - 12s 388ms/step - loss: 1.4616 - accuracy: 0.8217 - val_loss: 1.1085 - val_accuracy: 0.8468\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 12s 388ms/step - loss: 0.9117 - accuracy: 0.8476 - val_loss: 0.7298 - val_accuracy: 0.8486\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 15s 491ms/step - loss: 0.5662 - accuracy: 0.8810 - val_loss: 0.4502 - val_accuracy: 0.8967\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 15s 486ms/step - loss: 0.3733 - accuracy: 0.9097 - val_loss: 0.3296 - val_accuracy: 0.9094\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 15s 485ms/step - loss: 0.2779 - accuracy: 0.9216 - val_loss: 0.2648 - val_accuracy: 0.9149\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 15s 485ms/step - loss: 0.2229 - accuracy: 0.9313 - val_loss: 0.2342 - val_accuracy: 0.9197\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 15s 486ms/step - loss: 0.1912 - accuracy: 0.9385 - val_loss: 0.2172 - val_accuracy: 0.9215\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 16s 505ms/step - loss: 0.1699 - accuracy: 0.9436 - val_loss: 0.1967 - val_accuracy: 0.9258\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 15s 495ms/step - loss: 0.1486 - accuracy: 0.9513 - val_loss: 0.1915 - val_accuracy: 0.9286\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 15s 497ms/step - loss: 0.1329 - accuracy: 0.9571 - val_loss: 0.1855 - val_accuracy: 0.9301\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 16s 518ms/step - loss: 0.1168 - accuracy: 0.9639 - val_loss: 0.2002 - val_accuracy: 0.9291\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 15s 490ms/step - loss: 0.1050 - accuracy: 0.9679 - val_loss: 0.1946 - val_accuracy: 0.9314\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 15s 490ms/step - loss: 0.0955 - accuracy: 0.9712 - val_loss: 0.2027 - val_accuracy: 0.9278\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 15s 488ms/step - loss: 0.0899 - accuracy: 0.9735 - val_loss: 0.2058 - val_accuracy: 0.9327\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 15s 491ms/step - loss: 0.0846 - accuracy: 0.9759 - val_loss: 0.2147 - val_accuracy: 0.9301\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 15s 488ms/step - loss: 0.0766 - accuracy: 0.9787 - val_loss: 0.2207 - val_accuracy: 0.9273\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 15s 491ms/step - loss: 0.0716 - accuracy: 0.9806 - val_loss: 0.2324 - val_accuracy: 0.9289\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 15s 492ms/step - loss: 0.0673 - accuracy: 0.9820 - val_loss: 0.2273 - val_accuracy: 0.9278\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 15s 492ms/step - loss: 0.0644 - accuracy: 0.9830 - val_loss: 0.2356 - val_accuracy: 0.9306\n"
     ]
    }
   ],
   "source": [
    "tensorboard=TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
    "early_stopping=EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)  \n",
    "\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_val),\n",
    "                    callbacks=[tensorboard, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 106ms/step - loss: 0.2058 - accuracy: 0.9327\n",
      "494/494 [==============================] - 4s 8ms/step - loss: 0.0809 - accuracy: 0.9777\n",
      "\n",
      "\n",
      "Test score: 0.20582431554794312 \tTrain score:  0.0809110626578331\n",
      "Test accuracy: 0.9326582551002502 \tTrain accuracy:  0.9776554107666016\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_val, batch_size=batch_size, verbose=1)\n",
    "score_train = model.evaluate(x_train, y_train, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0], '\\tTrain score: ', score_train[0])\n",
    "print('Test accuracy:', score[1], '\\tTrain accuracy: ', score_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-11162dfa2a4ce6ef\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-11162dfa2a4ce6ef\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теперь инициализируем веса эмбеддингами word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for i in ([[sentence] for sentence in data.text.tolist()]):\n",
    "    corpus.append(i[0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['it', 'just', 'works'],\n",
       " ['целое',\n",
       "  'удобноной',\n",
       "  'приложение',\n",
       "  'минус',\n",
       "  'хотеть',\n",
       "  'большой',\n",
       "  'доступ',\n",
       "  'персональный',\n",
       "  'данные',\n",
       "  'телефонеприходиться',\n",
       "  'пользоваться',\n",
       "  'ограниченный',\n",
       "  'режим'],\n",
       " ['отлично'],\n",
       " ['зависать', 'работа', 'антивирус', 'ранее', 'пользоваться', 'нормальный'],\n",
       " ['удобно', 'работать', 'быстро']]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "обучим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(corpus, min_count = 5, workers=cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('удалить', 0.9989750385284424),\n",
       " ('установить', 0.9987788200378418),\n",
       " ('вирус', 0.9987732172012329),\n",
       " ('стоить', 0.998687207698822),\n",
       " ('ругаться', 0.9986011981964111),\n",
       " ('встроить', 0.9985995292663574),\n",
       " ('открытый', 0.9985509514808655),\n",
       " ('какой', 0.9985404014587402),\n",
       " ('pro', 0.9984924793243408),\n",
       " ('дело', 0.9984890818595886)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word('антивирус')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-2.22246423e-01, -6.75868213e-01,  6.79753944e-02, -4.37089503e-01,\n",
       "         4.04053926e-01,  8.54307972e-03, -9.25544277e-02,  6.67677298e-02,\n",
       "         1.72699198e-01,  7.84319818e-01,  2.29080513e-01,  1.50235966e-01,\n",
       "         2.96838917e-02, -5.17108977e-01,  1.32999271e-02,  1.33911595e-01,\n",
       "        -2.01028228e-01, -4.18809466e-02,  1.20318808e-01,  2.55722970e-01,\n",
       "        -9.69982624e-01,  9.04140234e-01,  5.69673479e-01,  3.33797991e-01,\n",
       "         1.01645088e+00, -9.95044596e-03,  2.90120929e-01,  2.86735892e-01,\n",
       "        -8.83910060e-02,  5.19492209e-01,  6.14972293e-01, -1.98781118e-02,\n",
       "         2.29031324e-01, -6.72626570e-02, -2.48865947e-01,  5.76577902e-01,\n",
       "        -1.51012644e-01,  3.79531711e-01,  4.19659823e-01,  7.44466903e-04,\n",
       "        -2.45349362e-01,  1.79774359e-01, -2.34059125e-01, -4.57110763e-01,\n",
       "         1.17608368e-01, -4.57845449e-01,  1.33840278e-01, -7.85816252e-01,\n",
       "         4.89292085e-01,  4.04952198e-01,  1.68620292e-02, -5.65115929e-01,\n",
       "        -6.79550946e-01, -6.91676378e-01,  2.63229996e-01, -4.64912266e-01,\n",
       "        -5.16259372e-02, -3.56889248e-01,  1.15443304e-01,  7.69964099e-01,\n",
       "         2.92806655e-01,  1.49653926e-01,  4.03283149e-01, -6.16802812e-01,\n",
       "        -2.44531468e-01, -3.62426221e-01, -2.53888756e-01, -4.58938688e-01,\n",
       "        -2.64618173e-02,  7.34585524e-02, -3.45219880e-01, -1.05694085e-02,\n",
       "        -2.38413349e-01,  4.86403346e-01,  2.86361277e-01,  3.07638526e-01,\n",
       "         3.47658806e-02,  2.78244037e-02,  2.13279814e-01,  3.32178652e-01,\n",
       "        -2.48312891e-01, -6.99467123e-01,  7.22508878e-03, -6.32092357e-02,\n",
       "        -4.47093137e-02,  3.74615230e-02,  4.65722336e-03, -6.37036800e-01,\n",
       "         1.46538585e-01,  5.15728779e-02,  9.28272307e-02,  8.77913758e-02,\n",
       "         3.74622077e-01, -6.85640812e-01, -2.33527154e-01,  2.72388104e-02,\n",
       "        -2.45995075e-01,  5.74591979e-02, -1.64213017e-01, -2.63018370e-01],\n",
       "       dtype=float32),\n",
       " (100,))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['антивирус'], model.wv['антивирус'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, у нас есть эмбеддинги для каждого слова в корпусе размером (100,).  \n",
    "Попробуем их сложить и получить матрицу, которую потом отправим в "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summ_ebm(txt):\n",
    "    summ_ = np.zeros(100)\n",
    "    for word in txt.split():\n",
    "        if word in model.wv:\n",
    "            summ_ += model.wv[word]\n",
    "    return summ_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_emb = pd.DataFrame(X_train)\n",
    "X_test_emb = pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_emb['sum_emb'] = X_train_emb.text.apply(summ_ebm)\n",
    "X_test_emb['sum_emb'] = X_test_emb.text.apply(summ_ebm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sum_emb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>классно</td>\n",
       "      <td>[-0.045559320598840714, -0.1767129898071289, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>невозможно использовать рутованный телефон</td>\n",
       "      <td>[-0.5540715865790844, -1.8357923179864883, 0.2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text  \\\n",
       "547                                      классно   \n",
       "1863  невозможно использовать рутованный телефон   \n",
       "\n",
       "                                                sum_emb  \n",
       "547   [-0.045559320598840714, -0.1767129898071289, 0...  \n",
       "1863  [-0.5540715865790844, -1.8357923179864883, 0.2...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_emb.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_emb = np.zeros((X_train_emb.shape[0], 100))\n",
    "xtest_emb = np.zeros((X_train_emb.shape[0], 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in tqdm(range(X_train_emb.shape[0])):\n",
    "#     xtrain_emb[i] = X_train_emb.iloc[i].sum_emb\n",
    "for i in range(X_train_emb.shape[0]):\n",
    "    xtrain_emb[i] = X_train_emb.iloc[i].sum_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15798, 100)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(X_test_emb.shape[0]):\n",
    "    xtest_emb[i] = X_test_emb.iloc[i].sum_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак мы получили матрицы из сумм эмбеддингов каждого слова в каждом отзыве. Попробуем засунуть теперь это в нейросеть в качестве весов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=100, input_length=max_len, weights=[xtrain_emb[:max_words]]))\n",
    "model.add(Conv1D(128, 3))\n",
    "model.add(Activation(\"relu\"))\n",
    "# model.add(AveragePooling1D())\n",
    "# model.add(Conv1D(256, 5))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(AveragePooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "# model.add(Conv1D(128, 3))\n",
    "# model.add(Activation('relu'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer='l2'))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=loss,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "31/31 [==============================] - 4s 131ms/step - loss: 2.5259 - accuracy: 0.7897 - val_loss: 1.5854 - val_accuracy: 0.8468\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 4s 131ms/step - loss: 1.3319 - accuracy: 0.8471 - val_loss: 0.9590 - val_accuracy: 0.8519\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 4s 138ms/step - loss: 0.8475 - accuracy: 0.8592 - val_loss: 0.7439 - val_accuracy: 0.8597\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 4s 127ms/step - loss: 0.9960 - accuracy: 0.8511 - val_loss: 1.1032 - val_accuracy: 0.8468\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 4s 131ms/step - loss: 0.9554 - accuracy: 0.8469 - val_loss: 0.8296 - val_accuracy: 0.8468\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 4s 132ms/step - loss: 0.7599 - accuracy: 0.8485 - val_loss: 0.6596 - val_accuracy: 0.8506\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 4s 126ms/step - loss: 0.6002 - accuracy: 0.8552 - val_loss: 0.5641 - val_accuracy: 0.8582\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 4s 134ms/step - loss: 0.5539 - accuracy: 0.8640 - val_loss: 0.5295 - val_accuracy: 0.8600\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 4s 126ms/step - loss: 0.5244 - accuracy: 0.8671 - val_loss: 0.5123 - val_accuracy: 0.8567\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 4s 127ms/step - loss: 0.5016 - accuracy: 0.8659 - val_loss: 0.4861 - val_accuracy: 0.8554\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 4s 127ms/step - loss: 0.4777 - accuracy: 0.8697 - val_loss: 0.4660 - val_accuracy: 0.8592\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 4s 125ms/step - loss: 0.4505 - accuracy: 0.8750 - val_loss: 0.4555 - val_accuracy: 0.8719\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 4s 127ms/step - loss: 0.5411 - accuracy: 0.8760 - val_loss: 0.6681 - val_accuracy: 0.8911\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 4s 126ms/step - loss: 0.5665 - accuracy: 0.8811 - val_loss: 0.4683 - val_accuracy: 0.8653\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 4s 128ms/step - loss: 0.4332 - accuracy: 0.8932 - val_loss: 0.4182 - val_accuracy: 0.8681\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 4s 135ms/step - loss: 0.3951 - accuracy: 0.8895 - val_loss: 0.3899 - val_accuracy: 0.8828\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 4s 131ms/step - loss: 0.3655 - accuracy: 0.9018 - val_loss: 0.3743 - val_accuracy: 0.8911\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 4s 126ms/step - loss: 0.3514 - accuracy: 0.9108 - val_loss: 0.3711 - val_accuracy: 0.9048\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 4s 125ms/step - loss: 0.3494 - accuracy: 0.9111 - val_loss: 0.3719 - val_accuracy: 0.8909\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 4s 126ms/step - loss: 0.3408 - accuracy: 0.9192 - val_loss: 0.3553 - val_accuracy: 0.9084\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 4s 126ms/step - loss: 0.3213 - accuracy: 0.9270 - val_loss: 0.3695 - val_accuracy: 0.9154\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 4s 126ms/step - loss: 0.3104 - accuracy: 0.9283 - val_loss: 0.3692 - val_accuracy: 0.9129\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 4s 126ms/step - loss: 0.3108 - accuracy: 0.9296 - val_loss: 0.3486 - val_accuracy: 0.9124\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 4s 126ms/step - loss: 0.2971 - accuracy: 0.9358 - val_loss: 0.3645 - val_accuracy: 0.9134\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 4s 129ms/step - loss: 0.2870 - accuracy: 0.9347 - val_loss: 0.3694 - val_accuracy: 0.9162\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 4s 128ms/step - loss: 0.2766 - accuracy: 0.9375 - val_loss: 0.3511 - val_accuracy: 0.9144\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 4s 128ms/step - loss: 0.2688 - accuracy: 0.9418 - val_loss: 0.3740 - val_accuracy: 0.9154\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 4s 128ms/step - loss: 0.2746 - accuracy: 0.9414 - val_loss: 0.3928 - val_accuracy: 0.9238\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 4s 128ms/step - loss: 0.2928 - accuracy: 0.9414 - val_loss: 0.3431 - val_accuracy: 0.9215\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 4s 129ms/step - loss: 0.2581 - accuracy: 0.9449 - val_loss: 0.3611 - val_accuracy: 0.9190\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 4s 128ms/step - loss: 0.3253 - accuracy: 0.9383 - val_loss: 0.3238 - val_accuracy: 0.9180\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 4s 129ms/step - loss: 0.3927 - accuracy: 0.9352 - val_loss: 0.3731 - val_accuracy: 0.9041\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 4s 129ms/step - loss: 0.2588 - accuracy: 0.9473 - val_loss: 0.3452 - val_accuracy: 0.9167\n"
     ]
    }
   ],
   "source": [
    "tensorboard=TensorBoard(log_dir='./logs_ext_weights', write_graph=True, write_images=True)\n",
    "early_stopping=EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)  \n",
    "\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_val),\n",
    "                    callbacks=[tensorboard, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 23ms/step - loss: 0.3928 - accuracy: 0.9238\n",
      "494/494 [==============================] - 1s 3ms/step - loss: 0.3182 - accuracy: 0.9509\n",
      "\n",
      "\n",
      "Test score: 0.39280107617378235 \tTrain score:  0.3182274103164673\n",
      "Test accuracy: 0.9237974882125854 \tTrain accuracy:  0.9508798718452454\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_val, batch_size=batch_size, verbose=1)\n",
    "score_train = model.evaluate(x_train, y_train, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0], '\\tTrain score: ', score_train[0])\n",
    "print('Test accuracy:', score[1], '\\tTrain accuracy: ', score_train[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
